{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e3f8fb7",
   "metadata": {},
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Ensemble Methods with Bank Marketing Dataset\\\\n\",\n",
    "    \"\\\\n\",\n",
    "    \"ဒီ Project မှာ Bank Marketing Dataset ကို အသုံးပြုပြီး ပိုမိုတိကျတဲ့ ခန့်မှန်းချက်တွေရဖို့ Ensemble Learning နည်းလမ်းတွေကို အသုံးပြုသွားမှာ ဖြစ်ပါတယ်။\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# 1. Libraries ခေါ်ယူခြင်း\\\\n\",\n",
    "    \"import pandas as pd\\\\n\",\n",
    "    \"import numpy as np\\\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\\\n\",\n",
    "    \"import seaborn as sns\\\\n\",\n",
    "    \"from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\\\\n\",\n",
    "    \"from sklearn.preprocessing import LabelEncoder, StandardScaler\\\\n\",\n",
    "    \"from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\\\\n\",\n",
    "    \"\\\\n\",\n",
    "    \"# Ensemble Models\\\\n\",\n",
    "    \"from sklearn.ensemble import RandomForestClassifier, VotingClassifier\\\\n\",\n",
    "    \"from xgboost import XGBClassifier\\\\n\",\n",
    "    \"\\\\n\",\n",
    "    \"import warnings\\\\n\",\n",
    "    \"warnings.filterwarnings('ignore')\\\\n\",\n",
    "    \"\\\\n\",\n",
    "    \"# 2. Data Load ပြုလုပ်ခြင်း\\\\n\",\n",
    "    \"DATA_PATH = r'bank.csv'  # သင့်ဖိုင်လမ်းကြောင်းအတိုင်းပြောင်းပါ\\\\n\",\n",
    "    \"df = pd.read_csv(DATA_PATH, sep=';')\\\\n\",\n",
    "    \"\\\\n\",\n",
    "    \"print('Data Loaded Successfully!')\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# 3. Feature Engineering (Data ပြင်ဆင်ခြင်း)\\\\n\",\n",
    "    \"# Categorical Columns များကို Numerical ပြောင်းလဲခြင်း\\\\n\",\n",
    "    \"categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\\\\n\",\n",
    "    \"categorical_cols.remove('y')\\\\n\",\n",
    "    \"\\\\n\",\n",
    "    \"label_encoders = {}\\\\n\",\n",
    "    \"for col in categorical_cols:\\\\n\",\n",
    "    \"    le = LabelEncoder()\\\\n\",\n",
    "    \"    df[col] = le.fit_transform(df[col])\\\\n\",\n",
    "    \"    label_encoders[col] = le\\\\n\",\n",
    "    \"\\\\n\",\n",
    "    \"df['y'] = (df['y'] == 'yes').astype(int)\\\\n\",\n",
    "    \"\\\\n\",\n",
    "    \"# Feature အသစ်များ ဖန်တီးခြင်း\\\\n\",\n",
    "    \"df['campaign_ratio'] = df['campaign'] / (df['pdays'] + 1)\\\\n\",\n",
    "    \"df['previous_contact'] = (df['previous'] > 0).astype(int)\\\\n\",\n",
    "    \"df['balance_per_age'] = df['balance'] / (df['age'] + 1)\\\\n\",\n",
    "    \"\\\\n\",\n",
    "    \"X = df.drop('y', axis=1)\\\\n\",\n",
    "    \"y = df['y']\\\\n\",\n",
    "    \"feature_names = X.columns.tolist()\\\\n\",\n",
    "    \"\\\\n\",\n",
    "    \"# Train/Test Split\\\\n\",\n",
    "    \"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\\\\n\",\n",
    "    \"\\\\n\",\n",
    "    \"print('Feature engineering completed.')\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# 4. Ensemble Method - 1: Random Forest (Bagging)\\\\n\",\n",
    "    \"print('\\\\n' + '='*50)\\\\n\",\n",
    "    \"print('RANDOM FOREST (BAGGING)')\\\\n\",\n",
    "    \"print('='*50)\\\\n\",\n",
    "    \"\\\\n\",\n",
    "    \"rf_params = {\\\\n\",\n",
    "    \"    'n_estimators': [100, 200, 300],\\\\n\",\n",
    "    \"    'max_depth': [10, 15, 20],\\\\n\",\n",
    "    \"    'min_samples_split': [5, 10],\\\\n\",\n",
    "    \"    'min_samples_leaf': [2, 5],\\\\n\",\n",
    "    \"    'max_features': ['sqrt', 'log2']\\\\n\",\n",
    "    \"}\\\\n\",\n",
    "    \"\\\\n\",\n",
    "    \"rf_base = RandomForestClassifier(random_state=42, n_jobs=-1)\\\\n\",\n",
    "    \"rf_grid = GridSearchCV(rf_base, rf_params, cv=5, scoring='accuracy', n_jobs=-1)\\\\n\",\n",
    "    \"rf_grid.fit(X_train, y_train)\\\\n\",\n",
    "    \"\\\\n\",\n",
    "    \"best_rf = rf_grid.best_estimator_\\\\n\",\n",
    "    \"print('Best Parameters:', rf_grid.best_params_)\\\\n\",\n",
    "    \"\\\\n\",\n",
    "    \"y_pred_rf = best_rf.predict(X_test)\\\\n\",\n",
    "    \"rf_acc = accuracy_score(y_test, y_pred_rf)\\\\n\",\n",
    "    \"print(f'Test Accuracy: {rf_acc:.4f}')\\\\n\",\n",
    "    \"print('\\\\nClassification Report:')\\\\n\",\n",
    "    \"print(classification_report(y_test, y_pred_rf))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# 5. Ensemble Method - 2: XGBoost (Boosting)\\\\n\",\n",
    "    \"print('\\\\n' + '='*50)\\\\n\",\n",
    "    \"print('XGBOOST (BOOSTING)')\\\\n\",\n",
    "    \"print('='*50)\\\\n\",\n",
    "    \"\\\\n\",\n",
    "    \"xgb_params = {\\\\n\",\n",
    "    \"    'n_estimators': [100, 200, 300],\\\\n\",\n",
    "    \"    'learning_rate': [0.01, 0.05, 0.1],\\\\n\",\n",
    "    \"    'max_depth': [3, 5, 7],\\\\n\",\n",
    "    \"    'subsample': [0.8, 1.0],\\\\n\",\n",
    "    \"    'colsample_bytree': [0.8, 1.0]\\\\n\",\n",
    "    \"}\\\\n\",\n",
    "    \"\\\\n\",\n",
    "    \"xgb_base = XGBClassifier(random_state=42, eval_metric='logloss', use_label_encoder=False)\\\\n\",\n",
    "    \"xgb_grid = GridSearchCV(xgb_base, xgb_params, cv=5, scoring='accuracy', n_jobs=-1)\\\\n\",\n",
    "    \"xgb_grid.fit(X_train, y_train)\\\\n\",\n",
    "    \"\\\\n\",\n",
    "    \"best_xgb = xgb_grid.best_estimator_\\\\n\",\n",
    "    \"print('Best Parameters:', xgb_grid.best_params_)\\\\n\",\n",
    "    \"\\\\n\",\n",
    "    \"y_pred_xgb = best_xgb.predict(X_test)\\\\n\",\n",
    "    \"xgb_acc = accuracy_score(y_test, y_pred_xgb)\\\\n\",\n",
    "    \"print(f'Test Accuracy: {xgb_acc:.4f}')\\\\n\",\n",
    "    \"print('\\\\nClassification Report:')\\\\n\",\n",
    "    \"print(classification_report(y_test, y_pred_xgb))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# 6. Ensemble Method - 3: Voting Classifier (Hybrid)\\\\n\",\n",
    "    \"print('\\\\n' + '='*50)\\\\n\",\n",
    "    \"print('VOTING CLASSIFIER (HYBRID)')\\\\n\",\n",
    "    \"print('='*50)\\\\n\",\n",
    "    \"\\\\n\",\n",
    "    \"voting_model = VotingClassifier(\\\\n\",\n",
    "    \"    estimators=[('rf', best_rf), ('xgb', best_xgb)],\\\\n\",\n",
    "    \"    voting='soft'\\\\n\",\n",
    "    \")\\\\n\",\n",
    "    \"voting_model.fit(X_train, y_train)\\\\n\",\n",
    "    \"\\\\n\",\n",
    "    \"y_pred_vote = voting_model.predict(X_test)\\\\n\",\n",
    "    \"vote_acc = accuracy_score(y_test, y_pred_vote)\\\\n\",\n",
    "    \"\\\\n\",\n",
    "    \"print(f'Test Accuracy: {vote_acc:.4f}')\\\\n\",\n",
    "    \"print('\\\\nClassification Report:')\\\\n\",\n",
    "    \"print(classification_report(y_test, y_pred_vote))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# 7. Results Comparison\\\\n\",\n",
    "    \"results = pd.DataFrame({\\\\n\",\n",
    "    \"    'Model': ['Random Forest (Bagging)', 'XGBoost (Boosting)', 'Voting (Hybrid)'],\\\\n\",\n",
    "    \"    'Accuracy': [rf_acc, xgb_acc, vote_acc]\\\\n\",\n",
    "    \"}).sort_values('Accuracy', ascending=False)\\\\n\",\n",
    "    \"\\\\n\",\n",
    "    \"print('\\\\n' + '='*50)\\\\n\",\n",
    "    \"print('MODEL COMPARISON')\\\\n\",\n",
    "    \"print('='*50)\\\\n\",\n",
    "    \"print(results)\\\\n\",\n",
    "    \"\\\\n\",\n",
    "    \"plt.figure(figsize=(10, 6))\\\\n\",\n",
    "    \"sns.barplot(data=results, x='Accuracy', y='Model', palette='viridis')\\\\n\",\n",
    "    \"plt.title('Model Accuracy Comparison')\\\\n\",\n",
    "    \"plt.xlim(0.85, 0.95)  # ဒီဂဏန်းတွေကို ကိုယ့်ရလဒ်အရ ပြင်ပါ\\\\n\",\n",
    "    \"plt.xlabel('Accuracy')\\\\n\",\n",
    "    \"plt.tight_layout()\\\\n\",\n",
    "    \"plt.savefig('model_comparison.png', dpi=300)\\\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.12.4\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 5\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
